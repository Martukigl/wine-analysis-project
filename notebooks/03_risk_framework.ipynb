{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f8fcf8",
   "metadata": {},
   "source": [
    "# Risk Framework — Decision Rules & Evaluation Strategy\n",
    "\n",
    "This notebook defines the **risk framing**, **business objective**, and **evaluation strategy** for a preventive wine-quality screening model.\n",
    "\n",
    "**Important scope rules**\n",
    "- No model training in this notebook.\n",
    "- No new metrics computed in this notebook.\n",
    "- This notebook sets the decision logic that will be implemented in `04_risk_modeling.ipynb` and used operationally in `05_risk_calculator.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d03c1",
   "metadata": {},
   "source": [
    "## 1) Technical risk definition (target variable)\n",
    "\n",
    "We reframe the original ordinal `quality` score into a **binary risk event**.\n",
    "\n",
    "- **High Risk (risk = 1):** `quality ≤ 5`\n",
    "- **Low Risk (risk = 0):** `quality > 5`\n",
    "\n",
    "This turns the problem into a **binary classification task**: predict whether a wine is likely to be technically low-quality **before market release**, using only physicochemical features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd894bb",
   "metadata": {},
   "source": [
    "## 2) Business context and cost asymmetry\n",
    "\n",
    "This model is designed as an **early warning system** for conservative decision-making.\n",
    "\n",
    "In this context, the costs of errors are asymmetric:\n",
    "\n",
    "- **False Negative (FN)**: a risky wine is predicted as safe (risk=0)  \n",
    "  - **Highest cost**: increases the chance of releasing low-quality wine.\n",
    "- **False Positive (FP)**: a safe wine is predicted as risky (risk=1)  \n",
    "  - **Lower cost**: triggers additional checks, rework, or delay.\n",
    "\n",
    "**Business priority:** minimize **False Negatives**, even if that produces more False Positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a745b6",
   "metadata": {},
   "source": [
    "## 3) Why accuracy is not the main metric\n",
    "\n",
    "Accuracy treats all errors equally and can be misleading in prevention problems.\n",
    "\n",
    "A model can achieve decent accuracy while still missing many risky wines—exactly the outcome we want to avoid.\n",
    "\n",
    "Because the business cost of **missing risk** is higher than the cost of **false alarms**, we do not optimize for accuracy as the primary objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5177f39",
   "metadata": {},
   "source": [
    "## 4) Primary objective metric: Recall for High Risk (risk = 1)\n",
    "\n",
    "**Recall (risk=1)** measures how many truly risky wines we successfully flag.\n",
    "\n",
    "- **Recall (risk=1) = TP / (TP + FN)**\n",
    "\n",
    "This metric directly aligns with the business goal of preventing missed risk cases.\n",
    "\n",
    "**Interpretation:** higher recall means fewer risky wines slipping through as “safe”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3b90b",
   "metadata": {},
   "source": [
    "## 5) Supporting metrics (why we still track them)\n",
    "\n",
    "Even with recall as the priority, we monitor additional metrics to ensure the model remains usable:\n",
    "\n",
    "- **Precision (risk=1)**: how many flagged wines are truly risky  \n",
    "  - Helps control the operational burden of too many false alarms.\n",
    "- **ROC-AUC**: measures ranking quality across thresholds  \n",
    "  - Useful for comparing models independent of a chosen threshold.\n",
    "- **PR-AUC**: focuses on performance on the positive class (risk=1)  \n",
    "  - Especially relevant when the positive class is the business focus.\n",
    "\n",
    "These metrics complement recall but do not replace it as the primary objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde58b2",
   "metadata": {},
   "source": [
    "## 6) Thresholding: 0.5 is a convention, not a business rule\n",
    "\n",
    "Most classifiers output a **risk probability** (or score). A **threshold** converts that probability into a decision:\n",
    "\n",
    "- If `P(risk=1) ≥ threshold` → predict **High Risk**\n",
    "- Else → predict **Low Risk**\n",
    "\n",
    "The default threshold **0.5** assumes equal error costs and equal priorities, which is **not true** here.\n",
    "\n",
    "Because **False Negatives are more costly**, we will likely choose a **lower threshold** than 0.5 to increase High-Risk recall (accepting more false positives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b891b9",
   "metadata": {},
   "source": [
    "## 7) Decision policy for selecting an operating threshold (to implement in Notebook 04)\n",
    "\n",
    "Threshold selection is a **business policy** informed by validation results.\n",
    "\n",
    "A practical approach aligned with this project:\n",
    "\n",
    "1. Choose a **minimum target recall** for High Risk (e.g., ≥ 0.85 or ≥ 0.90 on validation).\n",
    "2. Among thresholds that meet the recall target, select the one that:\n",
    "   - maximizes precision (reduces false alarms), and/or\n",
    "   - improves PR-AUC and overall stability.\n",
    "\n",
    "This creates a transparent, defensible trade-off between prevention (recall) and operational impact (precision).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e9e6c",
   "metadata": {},
   "source": [
    "## 8) Model comparison and selection rule (to implement in Notebook 04)\n",
    "\n",
    "In `04_risk_modeling.ipynb`, we will compare candidate models under the same train/validation protocol.\n",
    "\n",
    "**Selection rule**\n",
    "- A model must first satisfy the **High-Risk recall target** on validation.\n",
    "- If multiple models satisfy the target, prefer the model with:\n",
    "  - higher precision (risk=1) at the chosen operating threshold,\n",
    "  - higher PR-AUC,\n",
    "  - stable performance (small variance across folds, if cross-validation is used),\n",
    "  - and strong interpretability where feasible.\n",
    "\n",
    "This keeps the project aligned with the prevention objective and supports explainability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29a093",
   "metadata": {},
   "source": [
    "## 9) Why probability calibration may be needed (to implement in Notebooks 04–05)\n",
    "\n",
    "The final deliverable includes a **risk calculator** used for decision support.\n",
    "\n",
    "If we present probabilities (e.g., “risk = 0.72”), we want them to be **calibrated**, meaning:\n",
    "\n",
    "- predicted probabilities match observed frequencies (on average)\n",
    "\n",
    "Calibration matters because:\n",
    "- a well-ranked model (good AUC) can still output poorly calibrated probabilities,\n",
    "- business rules may depend on probability cutoffs,\n",
    "- stakeholders interpret probabilities as real-world risk levels.\n",
    "\n",
    "Calibration will be evaluated later and applied if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48e436",
   "metadata": {},
   "source": [
    "## 10) Guardrails, assumptions, and limitations\n",
    "\n",
    "- This project identifies **associations**, not causal effects (correlation ≠ causation).\n",
    "- The model is trained on historical data; changes in production processes or measurement protocols can shift performance.\n",
    "- Risk framing is specific to the chosen threshold (`quality ≤ 5`); alternative definitions would require re-validation.\n",
    "- The model supports **screening and prevention**, not final quality certification.\n",
    "\n",
    "All subsequent modeling decisions must remain consistent with this framework.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
